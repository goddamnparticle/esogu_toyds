{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c715aad-0b3e-4576-98ec-e211e25c7686",
      "metadata": {
        "id": "1c715aad-0b3e-4576-98ec-e211e25c7686"
      },
      "source": [
        "## Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L \"https://drive.google.com/uc?export=download&id=1TRUoqAtnNTft35NQP2AnHSqxbmKizSi9&confirm=t\" -o ModelNet40_Binary.tar\n",
        "!mkdir -p ModelNet40_Binary\n",
        "!tar xvf ModelNet40_Binary.tar --directory ModelNet40_Binary > /dev/null 2>&1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BsY0mipYN1q",
        "outputId": "5f00e3a1-0f96-418c-d300-24f7306300fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100  300M  100  300M    0     0   106M      0  0:00:02  0:00:02 --:--:--  225M\n"
          ]
        }
      ],
      "id": "0BsY0mipYN1q"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9182b972-647a-4628-8232-4a578a388459",
      "metadata": {
        "id": "9182b972-647a-4628-8232-4a578a388459"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.datasets.folder import DatasetFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "DATA_PATH = \"./ModelNet40_Binary/\"\n",
        "BATCH_SIZE = 32\n",
        "USE_CPU = False\n",
        "NUM_EPOCHS = 1\n",
        "EXT = (\".npy\", )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cd4158ce-885a-400d-9a03-315e7c99f963",
      "metadata": {
        "id": "cd4158ce-885a-400d-9a03-315e7c99f963"
      },
      "outputs": [],
      "source": [
        "class CustomDS(DatasetFolder):\n",
        "    def __init__(\n",
        "        self,\n",
        "        root,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        loader=None,\n",
        "        is_valid_file=None,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            root,\n",
        "            loader,\n",
        "            EXT if is_valid_file is None else None,\n",
        "            transform=transform,\n",
        "            target_transform=target_transform,\n",
        "            is_valid_file=is_valid_file,\n",
        "        )\n",
        "\n",
        "def Normalize(points):\n",
        "    norm_pointcloud = points - np.mean(points, axis=0) \n",
        "    norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "    return norm_pointcloud\n",
        "\n",
        "def ToTensor(points):\n",
        "    return torch.from_numpy(points)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                                Normalize,\n",
        "                                ToTensor,\n",
        "                                ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "54971387-c1b7-4946-8d3c-78a33a8e5263",
      "metadata": {
        "id": "54971387-c1b7-4946-8d3c-78a33a8e5263",
        "outputId": "a8199af1-82dc-4e72-9ee9-82c7855e07e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fb55ab70150>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "loader = np.load\n",
        "train_dataset = CustomDS(root=DATA_PATH + \"train\", loader=loader, transform=transform)\n",
        "test_dataset = CustomDS(root=DATA_PATH + \"test\", loader=loader, transform=transform)\n",
        "\n",
        "trainDataLoader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers=2)\n",
        "testDataLoader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE, num_workers=2)\n",
        "trainDataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainDataLoader)"
      ],
      "metadata": {
        "id": "qL74TipkjNEl",
        "outputId": "67bf61ad-c289-4b43-b99f-41de4dcddf17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qL74TipkjNEl",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "307"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c43ba284-ae92-4500-b804-2ab2ff779cce",
      "metadata": {
        "id": "c43ba284-ae92-4500-b804-2ab2ff779cce"
      },
      "outputs": [],
      "source": [
        "def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        npoint:\n",
        "        radius:\n",
        "        nsample:\n",
        "        xyz: input points position data, [B, N, 3]\n",
        "        points: input points data, [B, N, D]\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, npoint, nsample, 3]\n",
        "        new_points: sampled points data, [B, npoint, nsample, 3+D]\n",
        "    \"\"\"\n",
        "    B, N, C = xyz.shape\n",
        "    S = npoint\n",
        "    fps_idx = farthest_point_sample(xyz, npoint)  # [B, npoint, C]\n",
        "    new_xyz = index_points(xyz, fps_idx)\n",
        "    idx = query_ball_point(radius, nsample, xyz, new_xyz)\n",
        "    grouped_xyz = index_points(xyz, idx)  # [B, npoint, nsample, C]\n",
        "    grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C)\n",
        "\n",
        "    if points is not None:\n",
        "        grouped_points = index_points(points, idx)\n",
        "        new_points = torch.cat(\n",
        "            [grouped_xyz_norm, grouped_points], dim=-1\n",
        "        )  # [B, npoint, nsample, C+D]\n",
        "    else:\n",
        "        new_points = grouped_xyz_norm\n",
        "\n",
        "    if returnfps:\n",
        "        return new_xyz, new_points, grouped_xyz, fps_idx\n",
        "    else:\n",
        "        return new_xyz, new_points\n",
        "\n",
        "\n",
        "def sample_and_group_all(xyz, points):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        xyz: input points position data, [B, N, 3]\n",
        "        points: input points data, [B, N, D]\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, 1, 3]\n",
        "        new_points: sampled points data, [B, 1, N, 3+D]\n",
        "    \"\"\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    new_xyz = torch.zeros(B, 1, C).to(device)\n",
        "    grouped_xyz = xyz.view(B, 1, N, C)\n",
        "    if points is not None:\n",
        "        new_points = torch.cat([grouped_xyz, points.view(B, 1, N, -1)], dim=-1)\n",
        "    else:\n",
        "        new_points = grouped_xyz\n",
        "    return new_xyz, new_points\n",
        "\n",
        "def random_point_dropout(batch_pc, max_dropout_ratio=0.875):\n",
        "    \"\"\"batch_pc: BxNx3\"\"\"\n",
        "    for b in range(batch_pc.shape[0]):\n",
        "        dropout_ratio = np.random.random() * max_dropout_ratio  # 0~0.875\n",
        "        drop_idx = np.where(np.random.random((batch_pc.shape[1])) <= dropout_ratio)[0]\n",
        "        if len(drop_idx) > 0:\n",
        "            batch_pc[b, drop_idx, :] = batch_pc[b, 0, :]  # set to the first point\n",
        "    return batch_pc\n",
        "\n",
        "def random_scale_point_cloud(batch_data, scale_low=0.8, scale_high=1.25):\n",
        "    \"\"\"Randomly scale the point cloud. Scale is per point cloud.\n",
        "    Input:\n",
        "        BxNx3 array, original batch of point clouds\n",
        "    Return:\n",
        "        BxNx3 array, scaled batch of point clouds\n",
        "    \"\"\"\n",
        "    B, N, C = batch_data.shape\n",
        "    scales = np.random.uniform(scale_low, scale_high, B)\n",
        "    for batch_index in range(B):\n",
        "        batch_data[batch_index, :, :] *= scales[batch_index]\n",
        "    return batch_data\n",
        "\n",
        "def shift_point_cloud(batch_data, shift_range=0.1):\n",
        "    \"\"\"Randomly shift point cloud. Shift is per point cloud.\n",
        "    Input:\n",
        "      BxNx3 array, original batch of point clouds\n",
        "    Return:\n",
        "      BxNx3 array, shifted batch of point clouds\n",
        "    \"\"\"\n",
        "    B, N, C = batch_data.shape\n",
        "    shifts = np.random.uniform(-shift_range, shift_range, (B, 3))\n",
        "    for batch_index in range(B):\n",
        "        batch_data[batch_index, :, :] += shifts[batch_index, :]\n",
        "    return batch_data\n",
        "\n",
        "def farthest_point_sample(xyz, npoint):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        xyz: pointcloud data, [B, N, 3]\n",
        "        npoint: number of samples\n",
        "    Return:\n",
        "        centroids: sampled pointcloud index, [B, npoint]\n",
        "    \"\"\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
        "    distance = torch.ones(B, N).to(device) * 1e10\n",
        "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
        "    for i in range(npoint):\n",
        "        centroids[:, i] = farthest\n",
        "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
        "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
        "        mask = dist < distance\n",
        "        distance[mask] = dist[mask]\n",
        "        farthest = torch.max(distance, -1)[1]\n",
        "    return centroids\n",
        "\n",
        "def index_points(points, idx):\n",
        "    \"\"\"\n",
        "\n",
        "    Input:\n",
        "        points: input points data, [B, N, C]\n",
        "        idx: sample index data, [B, S]\n",
        "    Return:\n",
        "        new_points:, indexed points data, [B, S, C]\n",
        "    \"\"\"\n",
        "    device = points.device\n",
        "    B = points.shape[0]\n",
        "    view_shape = list(idx.shape)\n",
        "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
        "    repeat_shape = list(idx.shape)\n",
        "    repeat_shape[0] = 1\n",
        "    batch_indices = (\n",
        "        torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
        "    )\n",
        "    new_points = points[batch_indices, idx, :]\n",
        "    return new_points\n",
        "\n",
        "def square_distance(src, dst):\n",
        "    \"\"\"\n",
        "    Calculate Euclid distance between each two points.\n",
        "\n",
        "    src^T * dst = xn * xm + yn * ym + zn * zm；\n",
        "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
        "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
        "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
        "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
        "\n",
        "    Input:\n",
        "        src: source points, [B, N, C]\n",
        "        dst: target points, [B, M, C]\n",
        "    Output:\n",
        "        dist: per-point square distance, [B, N, M]\n",
        "    \"\"\"\n",
        "    B, N, _ = src.shape\n",
        "    _, M, _ = dst.shape\n",
        "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
        "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
        "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
        "    return dist\n",
        "\n",
        "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        radius: local region radius\n",
        "        nsample: max sample number in local region\n",
        "        xyz: all points, [B, N, 3]\n",
        "        new_xyz: query points, [B, S, 3]\n",
        "    Return:\n",
        "        group_idx: grouped points index, [B, S, nsample]\n",
        "    \"\"\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    _, S, _ = new_xyz.shape\n",
        "    group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])\n",
        "    sqrdists = square_distance(new_xyz, xyz)\n",
        "    group_idx[sqrdists > radius**2] = N\n",
        "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
        "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])\n",
        "    mask = group_idx == N\n",
        "    group_idx[mask] = group_first[mask]\n",
        "\n",
        "    return group_idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fd9ded4b-6fd8-4a6c-a855-ca5c23f753d5",
      "metadata": {
        "id": "fd9ded4b-6fd8-4a6c-a855-ca5c23f753d5"
      },
      "outputs": [],
      "source": [
        "class PointNetSetAbstraction(nn.Module):\n",
        "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):\n",
        "        super().__init__()\n",
        "        self.npoint = npoint\n",
        "        self.radius = radius\n",
        "        self.nsample = nsample\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = in_channel\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
        "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
        "            last_channel = out_channel\n",
        "        self.group_all = group_all\n",
        "\n",
        "    def forward(self, xyz, points):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            xyz: input points position data, [B, C, N]\n",
        "            points: input points data, [B, D, N]\n",
        "        Return:\n",
        "            new_xyz: sampled points position data, [B, C, S]\n",
        "            new_points_concat: sample points feature data, [B, D', S]\n",
        "        \"\"\"\n",
        "        xyz = xyz.permute(0, 2, 1)\n",
        "        if points is not None:\n",
        "            points = points.permute(0, 2, 1)\n",
        "\n",
        "        if self.group_all:\n",
        "            new_xyz, new_points = sample_and_group_all(xyz, points)\n",
        "        else:\n",
        "            new_xyz, new_points = sample_and_group(\n",
        "                self.npoint, self.radius, self.nsample, xyz, points\n",
        "            )\n",
        "        # new_xyz: sampled points position data, [B, npoint, C]\n",
        "        # new_points: sampled points data, [B, npoint, nsample, C+D]\n",
        "        new_points = new_points.permute(0, 3, 2, 1)  # [B, C+D, nsample,npoint]\n",
        "        for i, conv in enumerate(self.mlp_convs):\n",
        "            bn = self.mlp_bns[i]\n",
        "            new_points = F.relu(bn(conv(new_points)))\n",
        "\n",
        "        new_points = torch.max(new_points, 2)[0]\n",
        "        new_xyz = new_xyz.permute(0, 2, 1)\n",
        "        return new_xyz, new_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "956aef0a-addd-4f44-b569-932d19d60a3d",
      "metadata": {
        "id": "956aef0a-addd-4f44-b569-932d19d60a3d"
      },
      "outputs": [],
      "source": [
        "class PointNet(nn.Module):\n",
        "    def __init__(self, num_class, normal_channel=True):\n",
        "        super().__init__()\n",
        "        in_channel = 6 if normal_channel else 3\n",
        "        self.normal_channel = normal_channel\n",
        "        self.sa1 = PointNetSetAbstraction(npoint=512, radius=0.2, nsample=32, in_channel=in_channel, mlp=[64, 64, 128], group_all=False)\n",
        "        self.sa2 = PointNetSetAbstraction(npoint=128, radius=0.4, nsample=64, in_channel=128 + 3, mlp=[128, 128, 256], group_all=False)\n",
        "        self.sa3 = PointNetSetAbstraction(npoint=None, radius=None, nsample=None, in_channel=256 + 3, mlp=[256, 512, 1024], group_all=True)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.drop1 = nn.Dropout(0.4)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.drop2 = nn.Dropout(0.4)\n",
        "        self.fc3 = nn.Linear(256, num_class)\n",
        "\n",
        "    def forward(self, xyz):\n",
        "        B, _, _ = xyz.shape\n",
        "        if self.normal_channel:\n",
        "            norm = xyz[:, 3:, :]\n",
        "            xyz = xyz[:, :3, :]\n",
        "        else:\n",
        "            norm = None\n",
        "        l1_xyz, l1_points = self.sa1(xyz, norm)\n",
        "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
        "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
        "        x = l3_points.view(B, 1024)\n",
        "        x = self.drop1(F.relu(self.bn1(self.fc1(x))))\n",
        "        x = self.drop2(F.relu(self.bn2(self.fc2(x))))\n",
        "        x = self.fc3(x)\n",
        "        x = F.log_softmax(x, -1)\n",
        "        return x, l3_points\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "04c82c5e-2496-48c7-86a1-4487a204f36a",
      "metadata": {
        "id": "04c82c5e-2496-48c7-86a1-4487a204f36a"
      },
      "outputs": [],
      "source": [
        "class Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, target, trans_feat):\n",
        "        total_loss = F.nll_loss(pred, target)\n",
        "\n",
        "        return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "63d950cd-107b-4afe-ad00-54e5b0644423",
      "metadata": {
        "id": "63d950cd-107b-4afe-ad00-54e5b0644423"
      },
      "outputs": [],
      "source": [
        "classifier = PointNet(num_class=40, normal_channel=False).to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c7becd2c-cae3-42fb-aaa0-dca67e20bb5c",
      "metadata": {
        "id": "c7becd2c-cae3-42fb-aaa0-dca67e20bb5c"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    classifier.parameters(),\n",
        "    lr=1e-3,\n",
        "    betas=(0.9, 0.999),\n",
        "    eps=1e-08,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)\n",
        "criterion = Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4fb7fa8-82fa-465a-86cb-9d17e63070b9",
      "metadata": {
        "id": "d4fb7fa8-82fa-465a-86cb-9d17e63070b9",
        "outputId": "6b743476-3f31-459d-ed33-5a6e01c39eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            " 24%|██▍       | 75/307 [00:29<01:13,  3.17it/s]"
          ]
        }
      ],
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    mean_correct = []\n",
        "    classifier = classifier.train()\n",
        "    scheduler.step()\n",
        "\n",
        "    for batch_id, (points, target) in tqdm(\n",
        "        enumerate(trainDataLoader), total=len(trainDataLoader)\n",
        "    ):\n",
        "        optimizer.zero_grad()\n",
        "        points = points.squeeze(1)\n",
        "        points = points.data.numpy()\n",
        "        points = random_point_dropout(points)\n",
        "        points[:, :, 0:3] = random_scale_point_cloud(points[:, :, 0:3])\n",
        "        points[:, :, 0:3] = shift_point_cloud(points[:, :, 0:3])\n",
        "        points = torch.Tensor(points)\n",
        "        points = points.transpose(2, 1)\n",
        "\n",
        "        if not USE_CPU:\n",
        "            points, target = points.cuda(), target.cuda()\n",
        "\n",
        "        pred, trans_feat = classifier(points)\n",
        "        loss = criterion(pred, target.long(), trans_feat)\n",
        "        pred_choice = pred.data.max(1)[1]\n",
        "\n",
        "        correct = pred_choice.eq(target.long().data).cpu().sum()\n",
        "        mean_correct.append(correct.item() / float(points.size()[0]))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_instance_acc = np.mean(mean_correct)\n",
        "    print(f\"Train instance accuracy: {train_instance_acc:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "train_notebook.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}